#!/bin/bash
#
#                         License
#
# Copyright (C) 2021  David Valin dvalin@redhat.com
#
# This program is free software; you can redistribute it and/or
# modify it under the terms of the GNU General Public License
# as published by the Free Software Foundation; either version 2
# of the License, or (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program; if not, write to the Free Software
# Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
#
# Automate the exection of the fio workload.

test_name="fio"
arguments="$@"
disk_options=""
curdir=`pwd`

provide_disks()
{
	echo You need to designate disks, following are currently not mounted.
	tools_bin/grab_disks grab_disks
	cat disks
	echo "Enter comma separated list of devices to use: "
	read devices_to_use
	device_list=`echo $devices_to_use | sed "s/,/,\/dev\//g"`
	device_list=/dev/${device_list}
	disk_options="--disks ${device_list}"
}

gen_args_back="$@"
disks_found=0
i=1
j=$#
while [ $i -le $j ]
do
        #
        # Ansible causing problems again, getting passed }} for some reason from random workloads, filter it out.
        #
        case "$1" in
		--disks)
			disks_found=1
			break
		;;
		--usage)
			#
			# Do not need disks
			#
			disks_found=1
			break
		;;
		--)
			break
		;;
		*)
			i=$((i + 1))
			shift 1
		;;
	esac
done

if [ $disks_found -eq 0 ]; then
        provide_disks
fi

set -- ${gen_args_back}

source ~/.bashrc

curdir=`pwd`

if [[ $0 == "./"* ]]; then
	chars=`echo $0 | awk -v RS='/' 'END{print NR-1}'`
	if [[ $chars == 1 ]]; then
		run_dir=`pwd`
	else
		run_dir=`echo $0 | cut -d'/' -f 1-${chars} | cut -d'.' -f2-`
		run_dir="${curdir}${run_dir}"
	fi
elif [[ $0 != "/"* ]]; then
	dir=`echo $0 | rev | cut -d'/' -f2- | rev`
	run_dir="${curdir}/${dir}"
else
	chars=`echo $0 | awk -v RS='/' 'END{print NR-1}'`
	run_dir=`echo $0 | cut -d'/' -f 1-${chars}`
	if [[ $run_dir != "/"* ]]; then
		run_dir=${curdir}/${run_dir}
	fi
fi

run_results="Ran"
iodepth_list=""
max_disks=""
ioengine="libaio"
block_size=""
test_type="read,write"
ct_disk_size="undef"
jobs_max=`lscpu | grep NUMA | grep CPU | wc -l`
if [ $jobs_max -eq 0 ]; then
	jobs_max=1
fi
jobs_min="1"
tested=0
run_time=120
disks_passed=""
tuning_info=""
disks=""
numb_disks=0
regression=0
io_engine_list=""
njobs=0
iodepth=0
disk_size=0
os_vendor=`uname -a | cut -d'.' -f8`
file_count=0
file_size=10
fs_type="xfs"
tools_git=https://github.com/redhat-performance/test_tools-wrappers
file_list=""
file_size_opt=""
lvm_disk=0
mount_location=/fio
etcd_opts=0
data_sync=0
mount_index=0
maximum_disks=0
jobs_list=""
working_dir=""
results_version="1.0"
RESULTSDIR=""
target_count=0

if [ ! -f "/tmp/${test_name}.out" ]; then
        command="${0} $@ ${disk_options}"
        $command &> /tmp/${test_name}.out
	rtc=$?
	if [ -f /tmp/${test_name}.out ]; then
        	cat /tmp/${test_name}.out
        	rm /tmp/${test_name}.out
	fi
        exit $rtc
fi

exit_out()
{
	echo $1
	exit $2
}

usage()
{
	echo "Usage: $0"
	echo "  --block_size: comma separated lists of block sizes to use"
	echo "  --disk_size: size in M, use this as the size of the disk instead of lsblk"
	echo "  --disks: comma separated list of disks to use."
	echo "  --ioengine: comma separated list of ioengines to use"
	echo "  --iodepth_list: how many ios are allowed outstanding"
	echo "  --jobs_list: comma separated list of jobs, overrides jobs max and jobs_min, numa_node means use"
	echo "    number of numa nodes or 2, which ever is greater"
	echo "  --jobs_max: maximum number of jobs to run"
	echo "  --jobs_min: minimum number of jobs to run"
	echo "  --max_disks: maximum number of disks to run with"
	echo "  --max_disks_only: Perform the run only with maximum disks"
	echo "  --regression: regression run"
	echo "  --runtime: run for the designated period, 60 seconds is the default"
	echo "  --test_type: type of io doing."
	source test_tools/general_setup --usage
}
#
# Clone the repo that contains the common code and tools
#
found=0
for arg in "$@"; do
	if [ $found -eq 1 ]; then
		tools_git=$arg
		found=0
	fi
	if [[ $arg == "--tools_git" ]]; then
		found=1
	fi

	if [[ $found -eq 2 ]]; then
		string1=`echo $arg | cut -d: -f2 | sed "s/;/ /g"`
		for i in $string1; do
			if [[ $i == *"size"* ]]; then
				ct_disk_size=`echo $i | cut -d'=' -f 2`
				break
			fi
		done
	fi
	if [[ @arg == "--host_config" ]]; then
		found=2
	fi

	#
	# We do the usage check here, as we do not want to be calling
	# the common parsers then checking for usage here.  Doing so will
	# result in the script exiting with out giving the test options.
	#
	if [[ $arg == "--usage" ]]; then
		usage $0
	fi
done

#
# Check to see if the test tools directory exists.  If it does, we do not need to
# clone the repo.
#
if [ ! -d "test_tools" ]; then
	git clone $tools_git test_tools
	if [ $? -ne 0 ]; then
		exit_out "pulling git $tools_git failed." 1
	fi
fi

# Variables set by general setup.
#
# TOOLS_BIN: points to the tool directory
# to_home_root: home directory
# to_configuration: configuration information
# to_times_to_run: number of times to run the test
# to_user: User on the test system running the test
# to_sys_type: for results info, basically aws, azure or local
# to_sysname: name of the system
# to_tuned_setting: tuned setting
#

source test_tools/general_setup "$@"

#
# Report information
#
report_info()
{
	echo $1 >> /tmp/log
}

#
# Averaging function for json formatted bw and iops
#
obtain_avg()
{
        FIELD=${1}
        value=`jq '.. | select(type == "object" and has('\"$FIELD\"')).'\"$FIELD\"'' fio-results.json`
        nitems=0
        calc="scale=2;("
        field_separ=""
        for val in $value; do
                calc="${calc}${field_separ}$val"
                let "nitems=$nitems+1"
                field_separ="+"
        done
        if [ ${nitems} -eq 0 ]; then
		calc=0
	else
		# Divide by 3 since the json output includes all three I/O types and we only care about one
		calc="${calc})/(${nitems}/3)"
	fi
	rtval=`echo $calc | bc`
        echo $rtval
}

#
# A latency-specific averaging function to handle how the json output is formatted for clat, lat, and slat
#
obtain_avg_lat()
{
        FIELD=${1}
        value=`jq '.. | select(type == "object" and has('\"$FIELD\"')).'\"$FIELD\"'.mean' fio-results.json`
        nitems=0
        calc="scale=2;("
        field_separ=""
        for val in $value; do
                calc="${calc}${field_separ}$val"
                let "nitems=$nitems+1"
                field_separ="+"
        done
        if [ ${nitems} -eq 0 ]; then
		calc=0
	else
		# Divide by 3 since the json output includes all three I/O types and we only care about one
        	# Divide by 1000 because the json output is nsec but usec is a bit more friendly for now
        	calc="${calc})/(${nitems}/3)/1000"
	fi
        rtval=`echo $calc | bc`
        echo $rtval
}


reduce_data()
{
	file=`ls -d fio* | head -n 1`

	#
	# Build the sub_dirs
	#
	rm -rf results*
	cd $file
	for list in `ls`; do
		if [ -d "$list" ]; then
			fname=`echo $list | cut -d'-' -f 2-30`
			mkdir ../results_${fname}
		fi
	done
	cd ..
	rdir=`pwd`

	#
	# Now copy things to the proper place.
	#
	for list in `ls -d fio*`; do
		pushd $list > /dev/null
		njobs=`echo $list | cut -d'_' -f 8`
		iodepth=`echo $list | cut -d'_'  -f 12`
		ndisks=`echo $list | cut -d'_'  -f 3`
		for dir in `ls`; do
			if [ -d "$dir" ]; then
				fname=`echo $dir | cut -d'-' -f 2-30`
				cd $dir
				bw=$(obtain_avg "bw_mean")
				iops=$(obtain_avg "iops")
				clat=$(obtain_avg_lat "clat_ns")
                                slat=$(obtain_avg_lat "slat_ns")
                                lat=$(obtain_avg_lat "lat_ns")
				echo "${njobs}:${ndisks}:${iodepth}:${bw}" >> $rdir/results_${fname}/results_bw.csv
				echo "${njobs}:${ndisks}:${iodepth}:${iops}" >> $rdir/results_${fname}/results_iops.csv
				echo "${njobs}:${ndisks}:${iodepth}:${slat}" >> $rdir/results_${fname}/results_slat.csv
				echo "${njobs}:${ndisks}:${iodepth}:${clat}" >> $rdir/results_${fname}/results_clat.csv
				echo "${njobs}:${ndisks}:${iodepth}:${lat}" >> $rdir/results_${fname}/results_lat.csv
				cd ..
			fi
		done
		cp ${curdir}/meta_data.yml ${curdir}/export_fio_data
		popd > /dev/null
	done

	#
	# Now sort the results csv files and place headers
	#
	$TOOLS_BIN/test_header_info --front_matter --results_file $working_dir/results_fio.csv --host $to_configuration --sys_type $to_sys_type --tuned $to_tuned_setting --results_version $results_version --test_name $test_name
	for list in `ls -d results_*`; do
		pushd $list > /dev/null
		op_and_size=`echo $list | cut -d'_' -f 2`
		op=`echo "$op_and_size" | cut -d'-' -f1`
		size=`echo "$op_and_size" | cut -d'-' -f2`
		for ifile in `ls res*`; do
			$TOOLS_BIN/test_header_info --test_name ${test_name}  --info_in_dir_name "$file 2,3 4,5,6 7,8 9,10" --meta_output "op: $op" --meta_output "size: $size" --results_file results.csv
			if [[ $ifile == *"bw"* ]]; then
				echo "njobs:ndisks:iodepth:bw" >> results.csv
			fi
			if [[ $ifile == *"iops"* ]]; then
                                echo "njobs:ndisks:iodepth:iops" >> results.csv
                        fi
			if [[ $ifile == *"_lat"* ]]; then
				echo "njobs:ndisks:iodepth:lat" >> results.csv
			fi
			if [[ $ifile == *"_clat"* ]]; then
				echo "njobs:ndisks:iodepth:clat" >> results.csv
			fi
			if [[ $ifile == *"_slat"* ]]; then
				echo "njobs:ndisks:iodepth:slat" >> results.csv
			fi
			sort -t : -k 3 -n $ifile >> results.csv
			echo "" >> results.csv

			cat  results.csv >> $working_dir/results_fio.csv
			rm results.csv
		done
		popd > /dev/null
	done
}

reduce_io_data()
{
	aio_type=`ls -d fio* | cut -d'_' -f 10 | sort -u`

	#
	# First organize the data
	#
	for io_eng in $aio_type; do
		mkdir $io_eng
		cp -R *ioengine_${io_eng}* $io_eng
		pushd $io_eng
		numb_disks=`ls -d fio* | cut -d'_' -f 3 | sort -u`
		for ndisks in $numb_disks; do
			mkdir disks_${ndisks}
			mv fio_ndisks_${ndisks}* disks_${ndisks}
		done
		popd
	done

	#
	# Now process the fio data
	#
	for io_eng in $aio_type; do
		pushd $io_eng
		for disks in `ls -d disk*`; do
			pushd $disks
			reduce_data
			popd
		done
	done
}
	
# Create the required file systems.
#
create_and_mount_fs()
{
	dev_prefix="/dev"
	disks_recorded=1
	cd $to_home_root/$to_user

	seper=""
	if [ $lvm_disk -eq 1 ]; then
		#
		# As we are using lvm, there will only be one disk
		#
		numb_disks=1
		max_disks=1
		umount /perf1
		#
		# LVM requested.
		#
		lvm_disk_to_use=`echo $disks | sed "s/ /,/g"`
		$TOOLS_BIN/lvm_create --devices ${lvm_disk_to_use} --lvm_vol fio --lvm_grp fio
		if [ $? -ne 0 ]; then
			exit_out "$TOOLS_BIN/lvm_create --devices ${lvm_disk_to_use} --lvm_vol fio --lvm_grp fio failed" 1
		fi
		#
		# Sanity setup
		#
		mkdir /perf1
		#
		# Create the filesystem.
		#
		$TOOLS_BIN/create_filesystem --fs_type $fs_type --mount_dir /perf1 --device /dev/fio/fio
		if [ $? -ne 0 ]; then
			exit_out "$TOOLS_BIN/create_filesystem --fs_type $fs_type --mount_dir /perf1 --device /dev/fio/fio failed" 1
		fi
		#
		# Build the file list.
		#
		for findex in `seq 1 1 $file_count`; do
			file_list=${file_list}${seper}/perf1/fio_file_${findex}
			seper=" "
		done
	else
		disks=`echo $disks | sed "s/,/ /g"`
		#
		# For each disk.
		#
		for device in $disks; do
			mount_pnt=${mount_location}${mount_index}
			#
			# Sanity setup.
			#
			umount $mount_pnt >& /dev/null
			mkdir -p ${mount_pnt} >& /dev/null
			$TOOLS_BIN/create_filesystem --fs_type $fs_type --mount_dir $mount_pnt --device $device
			if [ $? -ne 0 ]; then
				exit_out "$TOOLS_BIN/create_filesystem --fs_type $fs_type --mount_dir /perf1 --device /dev/fio/fio failed" 1
			fi
			mount_list=${mount_list}${seper}${mount_pnt}
			seper=" "
			let "mount_index=${mount_index}+1"
			#
			# Build the file list for the mount point.
			#
			for findex in `seq 1 1 $file_count`; do
				file_list=${file_list}${seper}/${mount_pnt}/fio_file_${findex}
				seper=" "
			done
		done
	fi
	file_size_opt=${file_size}G
}

#
# Retrieve general system information and if doing regression run, set the proper variables.
#
setup_run_information()
{
	numa_nodes=`lscpu | grep NUMA | grep CPU | wc -l`
	numb_cpus=`lscpu | grep "^CPU(s)" | cut -d: -f 2`

	report_info "Numa nodes: ${numa_nodes}"
	report_info "cpus: ${numb_cpus}"

	#
	# Defaults common between regression runs and non regression runs.
	#
	if [[ $jobs_max == "" ]]; then
		jobs_max=$numa_nodes
	fi
	if [[ $max_disks == "" ]]; then
		max_disks=$numb_disks
	fi

	if [[ $iodepth_list == "" ]]; then
		if [ $regression -eq 1 ]; then
			iodepth_list="1 16 64"
		else
			iodepth_list="1 2 4 8 16 32"
		fi
	fi
	if [[ $block_size == "" ]]; then
		block_size="4,1024"
	fi
	io_engine_list=`echo $ioengine | sed "s/,/ /g"`
}


arguments="$@"

#
# Retrieve the disks to use.
#
obtain_disks()
{
	if [[ $disks_passed == "grab_disks" ]]; then
		results=`$TOOLS_BIN/grab_disks ${disks_passed}`
		
		#
		# If no disks have been passed in, bail.  Note we do not check
		# to make sure the disk exist.
		#
		if [ $? -ne 0 ]; then
			exit_out "grab disks failed." 1
		fi

		max_disks=`echo $results | cut -d: -f 2`
		disks=`echo $results | cut -d: -f 1`
	else
		disks=`echo $disks_passed | sed "s/,/ /g"`
		max_disks=`echo $disks | wc -w`
	fi
}

#
# Handle different locations of fio, and fix it so we will always find it
# in /usr/local/bin.  If we do not have fio, bail out with an error.
#
install_fio()
{
	#
	# fio may in /bin/fio but not /usr/local/bin/fio, handle the situation.
	#
	if [ -f "/usr/local/bin/fio" ]; then
		report_info "fio installed in /usr/local/bin/fio"
	else
		report_info "fio not installed in /usr/local/bin/fio, trying /bin/fio"
		if [ -f "/bin/fio" ]; then
			report_info "fio found in /bin/fio, copying to /usr/local/bin/fio"
			cp /bin/fio /usr/local/bin/fio
		else
			if [ -f "/usr/bin/fio" ]; then
				report_info "fio found in /usr/bin/fio, copying to /usr/local/bin/fio"
				cp /usr/bin/fio /usr/local/bin/fio
			else
				#
				# fio does not appear to be installed, bail out.
				#
				exit_out "fio does not exist in /bin either, aborting." 1
			fi
		fi
	fi
}

#
# Create the file we need  for runnig fio outside of pbench.
#
build_run_file()
{
	lio_size=$1
	lioe=$2
	liodepth=$3
	lnjobs=$4
	lrtime=$5
	ldisks_to_use=`echo $6 | sed "s/,/ /g"`
	lop=$7

	echo "[global]" > /tmp/fio_run
	echo "bs=${lio_size}" >> /tmp/fio_run
	echo "runtime=${lrtime}" >> /tmp/fio_run
	echo "ioengine=${lioe}" >> /tmp/fio_run
	echo "iodepth=${liodepth}" >> /tmp/fio_run
	echo "direct=1" >> /tmp/fio_run
	echo "sync=$data_sync" >> /tmp/fio_run
	echo "time_based=1" >> /tmp/fio_run
	echo "clocksource=gettimeofday" >> /tmp/fio_run
	echo "ramp_time=5" >> /tmp/fio_run
	echo "write_bw_log=fio" >> /tmp/fio_run
	echo "write_iops_log=fio" >> /tmp/fio_run
	echo "write_lat_log=fio" >> /tmp/fio_run
	if [[ $os_vendor != "amzn2" ]]; then
		echo "log_avg_msec=1000" >> /tmp/fio_run
		echo "write_hist_log=fio" >> /tmp/fio_run
		echo "log_hist_msec=10000" >> /tmp/fio_run
	fi
	echo " " >> /tmp/fio_run
	#
	# Cycle through the disks or files.
	#
	if [[ $file_list != "" ]]; then
		for file in $file_list; do
			echo "[job-${file}]" >> /tmp/fio_run
			echo "filename=${file}" >> /tmp/fio_run
			echo "rw=${lop}" >> /tmp/fio_run
			echo "size=${file_size_opt}" >> /tmp/fio_run
			echo "numjobs=$lnjobs" >> /tmp/fio_run
			echo " " >> /tmp/fio_run
		done
	else
		for disk in $ldisks_to_use; do
			echo "[job-${disk}]" >> /tmp/fio_run
			echo "filename=${disk}" >> /tmp/fio_run
			echo "rw=${lop}" >> /tmp/fio_run
			echo "size=${disk_size}" >> /tmp/fio_run
			echo "numjobs=$lnjobs" >> /tmp/fio_run
			echo " " >> /tmp/fio_run
		done
	fi
}

#
# Loop the io tests.
#
loop_io_tests()
{
	out_dir=$1
	disk_count=$2
	test_index=$3
	loop_io_size=$4

	for io_test in $use_test; do
		rdir=${out_dir}/${test_index}-${io_test}-${loop_io_size}KiB
		mkdir -p $rdir
		local_config="bs_${loop_io_size}_iod_${iodepth}_ndisks_${disk_count}_njobs_${njobs}_ioengine_${ioengine}"
		#
		# build the run file
		#
		build_run_file $ios $ioe $iodepth $njobs $run_time $disk_list $io_test
		cp /tmp/fio_run ${out_dir}/file_run_${test_index}
		let "test_index=${test_index}+1"
		fio --output-format=json /tmp/fio_run >> $rdir/fio-results.json
		mv *.log $rdir 		# preserve raw data
		lines=`wc -l $rdir/fio-results.json | cut -d' ' -f 1`
		if [ $lines -lt 2 ]; then
			run_results="Failed"
		fi
	done
}

#
# Iterate through the block sizes
#
loop_block_sizes()
{
	out_dir=$1
	disk_count=$2
	test_index=$3

	for io_size in $bs; do
		ios=$io_size
		loop_io_tests $out_dir $disk_count $test_index $io_size
	done
}

#
# Run fio outisde of the pbench harness.
#
fio_execute()
{
	disk_count=$2
	field_1=`date +%F | sed "s/-/./g"`
	field_2=`date +%H"."%M"."%S`

	use_test=`echo $test_type | sed "s/,/ /g"`
	bs=`echo $block_size | sed "s/,/ /g"`
	ioe=`echo $ioengine | sed "s/,/ /g"`
	test_index=1;

	for io_eng in $ioe; do
		out_dir="${curdir}/export_fio_data/fio_ndisks_${disk_count}_disksize_${ct_disk_size}_njobs_${njobs}_ioengine_${ioengine}_iodepth_${iodepth}_${field_1}T${field_2}"
		mkdir $out_dir
		loop_block_sizes $out_dir $disk_count $test_index
	done
}

#
# Perform the full run.
#
run_sweep()
{
	disks_to_use=0
	disks_used=1
	low_done=0
	disk_count=0

	#
	# Go through the disks. For testing purposes, we do 1,2 and then doubling of the
	# the number of disks.  Do not forget to do max disks.
	#

	if [ $maximum_disks -eq 1 ]; then
		disks_to_use=$max_disks
		target_count=$max_disks
		low_done=1
		disks_used=3
	fi
	for i in $disks; do
		if [ $disk_size -eq 0 ]; then
			disk_size=`lsblk -b --output SIZE -n -d $i`
		fi
		if [ $disk_count -gt $max_disks ]; then
			break
		fi
		#
		# We run 1 then 2 disks then double from there.
		#
		if [ $disks_used -le 2 ]; then
			if [ $disks_used == 1 ]; then
				disk_list=$i	
			else
				disk_list=$disk_list","$i
			fi
			let "disk_count=$disk_count+1"
			fio_execute $disk_list $disk_count
			if [ $lvm_disk -eq 1 ]; then
				break;
			fi
			let "disks_used=$disks_used+1"
			continue
		fi

		#	
		# Ok we now double the number of disks each time, up to the max disks
		#
		disk_list=$disk_list","$i
		let "disk_count=$disk_count+1"
		
		if [ $low_done -eq 0 ]; then
			low_done=1
			disks_to_use=4
		fi
		#
		# Run the test when we have the right number of disks.
		#
		if [ $disk_count -eq $disks_to_use ]; then
			#
			# First do the test, then bump $disks_to_use.
			#
			target_count=$disk_count
			fio_execute $disk_list $disk_count
			#
			# Did we just do max disks, if so break out.
			#
			if [ $disks_to_use -eq $max_disks ]; then
				break;
			fi
			#
			# Double the number of disks, if the results is greater then
			# max disks, then set disks_to_use to be max_disks.
			#
			let "disks_to_use=$disks_to_use*2"
			if [ $disks_to_use -gt $max_disks ]; then
				disks_to_use=$max_disks

			fi
		fi
	done
}

#
# We are doing a regression run.
#
run_regression()
{
	#
	# First one disk, then all of them.
	#
	disk_list=`echo $disks | cut -d' ' -f1`
	disk_size=`lsblk -b --output SIZE -n -d $disk_list`
	fio_execute $disk_list 1

	#
	# Now all of the disks
	#
	if [ $max_disks != 1 ]; then
		disk_list=`echo $disks | sed "s/ /,/g"`
		fio_execute $disk_list $max_disks
	fi
}

#
# Execute the fio test.  Loop for njobs, iodepth and ioegine.  run_sweep and run_regression
# will handle the disks.
#
execute_test()
{
	if [[ $jobs_list == "" ]]; then
		job_list_separ=""
		njobs=$jobs_min
		while [ $njobs -le $jobs_max ]; do
			jobs_list="${jobs_list}${job_list_separ}${njobs}"
			job_list_separ=","
			if [ $njobs -eq $jobs_max ]; then 
				break
			fi
			let "njobs=$njobs*2"
			#
			# Only do the max jobs designated.
			#
			if [ $njobs -gt $jobs_max ]; then
				njobs=$jobs_max
			fi
		done
	fi
	perform_jobs=`echo $jobs_list | sed "s/,/ /g"`

	# If we're using PCP start logging
    if [[ $to_use_pcp -eq 1 ]]; then
        echo "Start PCP"
        start_pcp ${pcpdir}/ ${test_name} $pcp_cfg
    fi

	for njobs in  ${perform_jobs}; do
		disk_used=0
		for iodepth in $iodepth_list; do
			tested=0
			for ioengine in  $io_engine_list; do
				if [[ $regression -eq 0 ]]; then
					run_sweep
				else
					run_regression
				fi
			done
		done
	done

	# If we're using PCP, stop logging
    if [[ $to_use_pcp -eq 1 ]]; then
        echo "Stop PCP"
        stop_pcp
	fi

	#
	# Done testing, process the results.
	#
	additional_info=`echo $additional_info | cut -d' ' -f 1`
	results_prefix=$additional_info"user_"$to_puser"_instance_"$to_sysname"_numb_disks_"$numb_disks"_"$tuning_info
	user=$additional_info"user_"$to_user"_instance_"$to_sysname"_numb_disks_"$numb_disks
	pushd $working_dir > /dev/null
	popd > /dev/null

	
		cp /tmp/log ${curdir}/export_fio_data
		rtdir=`pwd`
		cd ${curdir}/export_fio_data
		working_dir=`pwd`
		reduce_io_data
		cd $rtdir
		mv /tmp/${test_name}.out ${curdir}/export_fio_data
		echo $run_results >> ${curdir}/export_fio_data/test_results_report

	${curdir}/test_tools/save_results --curdir $curdir --home_root $to_home_root --copy_dir ${RESULTSDIR} --test_name $test_name --tuned_setting=$to_tuned_setting --version NONE --user $to_user
}

#
# Define options
#
ARGUMENT_LIST=(
	"block_size"
	"disks"
	"disk_size"
	"file_count"
	"file_size"
	"fs_type"
	"iodepth_list"
	"ioengine"
	"jobs_list"
	"jobs_max"
	"jobs_min"
	"max_disks"
	"runtime"
	"test_type"
)

NO_ARGUMENTS=(
	"debug"
	"etcd_opts"
	"help"
	"lvm"
	"max_disks_only"
	"regression"
)

#
# Make sure latest is installed. 

test_tools/package_tool --packages fio --no_packages $to_no_pkg_install
if [[ $? -ne 0 ]]; then
	exit_out "package_tool reported failure for fio package." 1
fi

# read arguments
opts=$(getopt \
	--longoptions "$(printf "%s:," "${ARGUMENT_LIST[@]}")" \
	--longoptions "$(printf "%s," "${NO_ARGUMENTS[@]}")" \
	--name "$(basename "$0")" \
	--options "h" \
	-- "$@"
)

eval set --$opts

while [[ $# -gt 0 ]]; do
	case "$1" in
		--block_size)
			block_size=${2}
			shift 2
		;;
		--disk_size)
			disk_size=${2}
			shift 2
		;;
		--disks)
			disks_passed=${2}
			shift 2
		;;
		--etcd_opts)
			test_name="etcd"
			etcd_opts=1
			shift 1
		;;
		--file_count)
			file_count=${2}
			shift 2
		;;
		--file_size)
			file_size=${2}
			shift 2
		;;
		--fs_type)
			fs_type=${2}
			shift 2
		;;
		--help)
			usage
		;;
		--iodepth_list)
			iodepth_list=${2}
			shift 2
		;;
		--ioengine)
			ioengine=${2}
			shift 2
		;;
		--lvm)
			lvm_disk=1
			shift 1
		;;
		--jobs_list)
			#
			# Need to convert "numa_node" to actual numa_node value
			#
			if [[ ${2} == *"numa_node"* ]];then
				numa_node=`lscpu | grep "NUMA node(s):"| cut -d ':' -f2 | sed "s/ //g"`
				if [[ $numa_node == "1" ]]; then
					numa_node=2
				fi
				jobs_list=`echo ${2} | sed "s/numa_node/${numa_node}/g"`
			else
				jobs_list=${2}
			fi
			shift 2
		;;
		--jobs_max)
			jobs_max=${2}
			shift 2
		;;
		--jobs_min)
			jobs_min=${2}
			shift 2
		;;
		--max_disks)
			max_disks=${2}
			shift 2
		;;
		--max_disks_only)
			maximum_disks=1
			shift 1
		;;
		--regression)
			regression=1
			shift 1
		;;
		--runtime)
			run_time=${2}
			shift 2
		;;
		--test_type)
			test_type=${2}
			shift 2
		;;
		-h)
			usage $0
		;;
		--)
			break; 
		;;
		*)
			report_info "option not found ${1}"
			usage $0
		;;
	esac
done
#
# Verify device info.
#
if [ $file_count -eq 0 ]; then
	#
	# Using disks
	#
	if [[ $disks_passed != "grab_disks" ]]; then
		device_list=`echo $disks_passed | sed "s/,/ /g"`
		for item in $device_list; do
			#dereference symlinks to handle things like multipath aliases in /dev/mapper
			value=`file -L $item` 	
			echo $value | grep "block special" > /dev/null
			if [ $? -ne 0 ]; then
				exit_out "Error: $item is not a block device" 1
			fi
			test_tools/detect_mounts $item
			if [ $? -ne 0 ]; then
				exit_out "Error: $item is mounted." 1
			fi
		done
	fi
fi

# Set up fresh results area
RESULTSDIR=${curdir}/export_fio_data_$(date "+%Y.%m.%d-%H.%M.%S")
rm export_fio_data
mkdir ${RESULTSDIR}
ln -s ${RESULTSDIR} ${curdir}/export_fio_data
# Make a PCP results directory if we need it
if [[ $to_use_pcp -eq 1 ]]; then
    pcpdir=${RESULTSDIR}/pcp
    mkdir ${pcpdir}
fi

install_fio
iodepth_list=`echo $iodepth_list | sed "s/,/ /g"`

obtain_disks


if [[ $ct_disk_size == "undef" ]]; then
	disk_temp=`mktemp /tmp/confg.XXXXX`
	disk_temp1=`mktemp /tmp/confg.XXXXX`
	#
	# Need the disk size, grab the size of the disks present.
	#
	disk_items=`echo $disks | sed "s/,/ /g"`
	for i in $disk_items; do
		fdisk -l $i | grep -P '^(?=.*Disk)(?=.*sectors)' | cut -d: -f2 | sed "s/ /_/g" | sed "s/,//g" | cut -d'_' -f2,3 >> $disk_temp
	done
	sort -u $disk_temp >> $disk_temp1
	ct_disk_size=""
	ct_disk_separ=""
	for i in `cat $disk_temp1`; do
		ct_disk_size=${i}${ct_disk_size}${ct_disk_separ}
		ct_disk_separ='_'
	done
	rm $disk_temp
	rm $disk_temp1
fi

setup_run_information

#
# Special run setup for etcd sim.
#
if [ $etcd_opts -eq 1 ]; then
	block_size=2300
	iodepth_list=1
	ioe=sync
	file_size_opt=22m
	data_sync=1
	jobs_min=1
	jobs_max=1
	njobs=1
	if [ $file_count -eq 0 ]; then
		file_count=1
	fi
fi

if [ $file_count -ne 0 ]; then
	#
	# Handle filesystem creation.
	#
	create_and_mount_fs
	pfile_list=`echo ${file_list} | sed "s/ /,/g"`
else
	#
	# Targets are the disks.
	#
	pdisk_list=`echo ${disks} | sed "s/ /,/g"`
fi

# Get PCP setup if we're using it
if [[ $to_use_pcp -eq 1 ]]; then
    source $TOOLS_BIN/pcp/pcp_commands.inc
    setup_pcp
    pcp_cfg=$TOOLS_BIN/pcp/default.cfg
fi

execute_test

# Shutdown PCP and clean up after ourselves
if [[ $to_use_pcp -eq 1 ]]; then
    shutdown_pcp
fi

if [ $file_count -ne 0 ]; then
	if [ $lvm_disk -eq 1 ]; then
		$TOOLS_BIN/lvm_delete --lvm_vol fio --lvm_grp fio --mount_pnt /perf1
	else
		$TOOLS_BIN/umount_filesystems --mount_pnt ${mount_location} --number_mount_pnts ${mount_index}
	fi
fi
exit 0
